<!DOCTYPE html>
<html lang="en-US">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math">
<h4 class="heading"><span class="type">Paragraph</span></h4>
<div class="para logical">
<div class="para">Perceptron: Consider the set <span class="process-math">\(S\)</span> of training datas with labels. In other words, an element of <span class="process-math">\(S\)</span> is a set of training data including a label field. A perceptron is a function <span class="process-math">\(f\)</span> from <span class="process-math">\(S\)</span> to the set of Threshold Functions such that the domain of f(x) is x. A Threshold Function is defined as follows:</div>
<div class="displaymath process-math">
\begin{equation*}
f(\mathbf{x})= \begin{cases}1  \text { if } \mathbf{w} \cdot \mathbf{x}+b&gt;0 \\ 0  \text { otherwise }\end{cases}
\end{equation*}
</div>
<div class="para">where <span class="process-math">\(\mathbf{x,w}\in\mathbb{R}^n\text{.}\)</span> Now, for Neural Networks the definition changes a little. And most other definitions for Neural Networks will be molded similarly defined. This time, the domain and codomain are the product <span class="process-math">\(S\times N_1\)</span> and <span class="process-math">\(N_1\)</span> respectively, where <span class="process-math">\(N_1\)</span> is the set of all single layer neurons.</div>
</div>
<span class="incontext"><a href="machine-learning.html#p-6" class="internal">in-context</a></span>
</body>
</html>
